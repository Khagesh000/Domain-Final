{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b70a6c1d",
   "metadata": {},
   "source": [
    "# for one person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b18f650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# Load the image of the person for face verification\n",
    "verification_image_path = r\"C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg\"  # Replace with the actual path\n",
    "verification_image = face_recognition.load_image_file(verification_image_path)\n",
    "verification_encoding = face_recognition.face_encodings(verification_image)[0]\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "    # Perform face verification\n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        name = knn_clf.predict([face_encoding])[0]\n",
    "        (top, right, bottom, left) = face_location\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        # Perform face verification\n",
    "        verification_result = face_recognition.compare_faces([verification_encoding], face_encoding)\n",
    "        if verification_result[0]:\n",
    "            # Display the name of the recognized person\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, f\"{name} (Verified)\", (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "        else:\n",
    "            cv2.putText(frame, \"Unverified\", (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f4443",
   "metadata": {},
   "source": [
    "# more faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba5267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    verification_encodings[person] = face_recognition.face_encodings(verification_image)[0]\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "    # Perform face verification\n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        name = knn_clf.predict([face_encoding])[0]\n",
    "        (top, right, bottom, left) = face_location\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        # Perform face verification with multiple verification images\n",
    "        for person, encoding in verification_encodings.items():\n",
    "            verification_result = face_recognition.compare_faces([encoding], face_encoding)\n",
    "            if verification_result[0]:\n",
    "                # Display the name of the recognized and verified person\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, f\"{name} (Verified as {person})\", (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9927cf4e",
   "metadata": {},
   "source": [
    "# in excel or txt logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b29bccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    verification_encodings[person] = face_recognition.face_encodings(verification_image)[0]\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# Log file to record recognition and verification events\n",
    "log_file_path = 'recognition_log.txt'\n",
    "\n",
    "# Metrics variables\n",
    "start_time = None\n",
    "total_recognitions = 0\n",
    "average_recognition_time = 0.0\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "    # Perform face verification\n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        name = knn_clf.predict([face_encoding])[0]\n",
    "        (top, right, bottom, left) = face_location\n",
    "\n",
    "        # Log recognition event\n",
    "        with open(log_file_path, 'a') as log_file:\n",
    "            log_file.write(f\"{datetime.datetime.now()} - Recognized: {name}\\n\")\n",
    "\n",
    "        # Log additional details of the person\n",
    "        with open(log_file_path, 'a') as log_file:\n",
    "            log_file.write(f\"Name: {name}\\n\")\n",
    "\n",
    "        # Display the name of the recognized and verified person\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, f\"{name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 0), 1)  # Yellow text\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        # Update metrics\n",
    "        total_recognitions += 1\n",
    "        if start_time is not None:\n",
    "            elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "            average_recognition_time = (average_recognition_time * (total_recognitions - 1) + elapsed_time) / total_recognitions\n",
    "\n",
    "        # Record start time for the next face\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "    # Display metrics on the frame\n",
    "    cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "    cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da3305c",
   "metadata": {},
   "source": [
    "# store single frame only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c038ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    verification_encodings[person] = face_recognition.face_encodings(verification_image)[0]\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# Log file to record recognition and verification events\n",
    "log_file_path = 'recognition_log.txt'\n",
    "\n",
    "# Folder to save recognized and verified faces\n",
    "output_folder = 'recognized_faces'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Metrics variables\n",
    "start_time = None\n",
    "total_recognitions = 0\n",
    "average_recognition_time = 0.0\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "    # Perform face verification\n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        name = knn_clf.predict([face_encoding])[0]\n",
    "        (top, right, bottom, left) = face_location\n",
    "\n",
    "        # Log recognition event\n",
    "        with open(log_file_path, 'a') as log_file:\n",
    "            log_file.write(f\"{datetime.datetime.now()} - Recognized: {name}\\n\")\n",
    "\n",
    "        # Log additional details of the person\n",
    "        with open(log_file_path, 'a') as log_file:\n",
    "            log_file.write(f\"Name: {name}\\n\")\n",
    "\n",
    "        # Display the name of the recognized and verified person\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, f\"{name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 0), 1)  # Yellow text\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        # Check if the recognized face is verified\n",
    "        if name in verification_encodings:\n",
    "            verification_result = face_recognition.compare_faces([verification_encodings[name]], face_encoding)\n",
    "            if verification_result[0]:\n",
    "                # Save the recognized and verified face to the output folder\n",
    "                face_image = frame[top:bottom, left:right]\n",
    "                face_filename = os.path.join(output_folder, f\"{name}_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "                cv2.imwrite(face_filename, face_image)\n",
    "\n",
    "                # Log verification event\n",
    "                with open(log_file_path, 'a') as log_file:\n",
    "                    log_file.write(f\"{datetime.datetime.now()} - Verified: {name}\\n\")\n",
    "\n",
    "        # Update metrics\n",
    "        total_recognitions += 1\n",
    "        if start_time is not None:\n",
    "            elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "            average_recognition_time = (average_recognition_time * (total_recognitions - 1) + elapsed_time) / total_recognitions\n",
    "\n",
    "        # Record start time for the next face\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "    # Display metrics on the frame\n",
    "    cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "    cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75da763e",
   "metadata": {},
   "source": [
    "# for many faces frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a9e2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'ABHI':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHI\\0.jpg',\n",
    "    'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "    'ABHIRAM':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHIRAM\\0.jpg',\n",
    "    'ABHISHIEK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHISHIEK\\0.jpg',\n",
    "    'ARUN':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ARUN\\0.jpg',\n",
    "    'BHEEMARAJU':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\BHEEMARAJU\\0.jpg',\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    verification_encodings[person] = face_recognition.face_encodings(verification_image)[0]\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# Log file to record recognition and verification events\n",
    "log_file_path = 'recognition_log.txt'\n",
    "\n",
    "# Folder to save all recognized faces\n",
    "output_folder = 'recognized_faces'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Metrics variables\n",
    "start_time = None\n",
    "total_recognitions = 0\n",
    "average_recognition_time = 0.0\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "    # Perform face verification\n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        name = knn_clf.predict([face_encoding])[0]\n",
    "        (top, right, bottom, left) = face_location\n",
    "\n",
    "        # Log recognition event\n",
    "        with open(log_file_path, 'a') as log_file:\n",
    "            log_file.write(f\"{datetime.datetime.now()} - Recognized: {name}\\n\")\n",
    "\n",
    "        # Log additional details of the person\n",
    "        with open(log_file_path, 'a') as log_file:\n",
    "            log_file.write(f\"Name: {name}\\n\")\n",
    "\n",
    "        # Display the name of the recognized person\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, f\"{name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 0), 1)  # Yellow text\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        # Save the recognized face to the output folder\n",
    "        face_image = frame[top:bottom, left:right]\n",
    "        face_filename = os.path.join(output_folder, f\"{name}_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "        cv2.imwrite(face_filename, face_image)\n",
    "\n",
    "        # Update metrics\n",
    "        total_recognitions += 1\n",
    "        if start_time is not None:\n",
    "            elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "            average_recognition_time = (average_recognition_time * (total_recognitions - 1) + elapsed_time) / total_recognitions\n",
    "\n",
    "        # Record start time for the next face\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "    # Display metrics on the frame\n",
    "    cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "    cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9518ff",
   "metadata": {},
   "source": [
    "# main code ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "531313ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in MOULI's image: C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MOULI\\14.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'ABHI':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHI\\0.jpg',\n",
    "    'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "    'ABHIRAM':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHIRAM\\0.jpg',\n",
    "    'ABHISHIEK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHISHIEK\\0.jpg',\n",
    "    'ARUN':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ARUN\\0.jpg',\n",
    "    'BHEEMARAJU':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\BHEEMARAJU\\0.jpg',\n",
    "    'GIRISH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GIRISH\\0.jpg',\n",
    "    'GOUSE':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOUSE\\0.jpg',\n",
    "    'GOWTHAM':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\0.jpg',\n",
    "    'KARTHIK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\KARTHIK\\0.jpg',\n",
    "    'KISHORE':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\KISHORE\\0.jpg',\n",
    "    'LAVAKUMAR':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\LAVAKUMAR\\0.jpg',\n",
    "    'LOKESH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\LOKESH\\15.jpg',\n",
    "    'MAHESH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MAHESH\\14.jpg',\n",
    "    'MANIKANTA':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MANIKANTA\\39.jpg',\n",
    "    'MOULI':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MOULI\\14.jpg',\n",
    "    'SURESH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\SURESH\\14.jpg',\n",
    "    'VARDHAN':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VARDHAN\\26.jpg',\n",
    "    'VIVEK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIVEK\\14.jpg',\n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    # Ensure that at least one face is detected\n",
    "    face_encodings = face_recognition.face_encodings(verification_image)\n",
    "    if face_encodings:\n",
    "        verification_encodings[person] = face_encodings[0]\n",
    "    else:\n",
    "        print(f\"No face detected in {person}'s image: {image_path}\")\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# Log file to record recognition and verification events\n",
    "log_file_path = 'recognition_log.txt'\n",
    "\n",
    "# Folder to save all recognized faces\n",
    "output_folder = 'recognized_faces'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Metrics variables\n",
    "start_time = None\n",
    "total_recognitions = 0\n",
    "average_recognition_time = 0.0\n",
    "confidence_threshold = 0.5  # Set the confidence threshold as needed\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    \n",
    "    # Ensure that there are face encodings\n",
    "    if len(face_locations) > 0:\n",
    "        face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "        # Perform face verification\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            name = knn_clf.predict([face_encoding])[0]\n",
    "            (top, right, bottom, left) = face_location\n",
    "\n",
    "            # Perform face recognition with confidence\n",
    "            face_distances = face_recognition.face_distance(list(verification_encodings.values()), face_encoding)\n",
    "            min_distance = min(face_distances)\n",
    "            if min_distance < confidence_threshold:\n",
    "                recognized_name = list(verification_encodings.keys())[list(face_distances).index(min_distance)]\n",
    "            else:\n",
    "                recognized_name = \"Unknown\"\n",
    "\n",
    "            # Log recognition event\n",
    "            with open(log_file_path, 'a') as log_file:\n",
    "                log_file.write(f\"{datetime.datetime.now()} - Recognized: {recognized_name}\\n\")\n",
    "\n",
    "            # Display the name of the recognized person\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, f\"{recognized_name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 0), 1)  # Yellow text\n",
    "\n",
    "            # Draw a rectangle around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "            # Save the recognized face to the output folder\n",
    "            face_image = frame[top:bottom, left:right]\n",
    "            face_filename = os.path.join(output_folder, f\"{recognized_name}_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "            cv2.imwrite(face_filename, face_image)\n",
    "\n",
    "            # Update metrics\n",
    "            total_recognitions += 1\n",
    "            if start_time is not None:\n",
    "                elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "                average_recognition_time = (average_recognition_time * (total_recognitions - 1) + elapsed_time) / total_recognitions\n",
    "\n",
    "            # Record start time for the next face\n",
    "            start_time = datetime.datetime.now()\n",
    "\n",
    "    # Display metrics on the frame\n",
    "    cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "    cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09361a4",
   "metadata": {},
   "source": [
    "# MAIN CODE ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41bec00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in MOULI's image: C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MOULI\\14.jpg\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import face_recognition\n",
    "# import pickle\n",
    "# import datetime\n",
    "# import os\n",
    "\n",
    "# # Load the trained KNN classifier\n",
    "# with open('trained_model.clf', 'rb') as f:\n",
    "#     knn_clf = pickle.load(f)\n",
    "\n",
    "# # Dictionary to store verification images and their encodings\n",
    "# verification_images = {\n",
    "#     'ABHI':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHI\\0.jpg',\n",
    "#     'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "#     'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "#     'ABHIRAM':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHIRAM\\0.jpg',\n",
    "#     'ABHISHIEK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHISHIEK\\0.jpg',\n",
    "#     'ARUN':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ARUN\\0.jpg',\n",
    "#     'BHEEMARAJU':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\BHEEMARAJU\\0.jpg',\n",
    "#     'GIRISH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GIRISH\\0.jpg',\n",
    "#     'GOUSE':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOUSE\\0.jpg',\n",
    "#     'GOWTHAM':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\0.jpg',\n",
    "#     'KARTHIK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\KARTHIK\\0.jpg',\n",
    "#     'KISHORE':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\KISHORE\\0.jpg',\n",
    "#     'LAVAKUMAR':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\LAVAKUMAR\\0.jpg',\n",
    "#     'LOKESH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\LOKESH\\15.jpg',\n",
    "#     'MAHESH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MAHESH\\14.jpg',\n",
    "#     'MANIKANTA':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MANIKANTA\\39.jpg',\n",
    "#     'MOULI':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MOULI\\14.jpg',\n",
    "#     'SURESH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\SURESH\\14.jpg',\n",
    "#     'VARDHAN':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VARDHAN\\26.jpg',\n",
    "#     'VIVEK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIVEK\\14.jpg',\n",
    "#     # Add more persons as needed\n",
    "# }\n",
    "\n",
    "# # Load verification images and their encodings\n",
    "# verification_encodings = {}\n",
    "# for person, image_path in verification_images.items():\n",
    "#     verification_image = face_recognition.load_image_file(image_path)\n",
    "#     # Ensure that at least one face is detected\n",
    "#     face_encodings = face_recognition.face_encodings(verification_image)\n",
    "#     if face_encodings:\n",
    "#         verification_encodings[person] = face_encodings[0]\n",
    "#     else:\n",
    "#         print(f\"No face detected in {person}'s image: {image_path}\")\n",
    "\n",
    "# # Open the video capture\n",
    "# video = cv2.VideoCapture(1)\n",
    "\n",
    "# # Log file to record recognition and verification events\n",
    "# log_file_path = 'recognition_log.txt'\n",
    "\n",
    "# # Folder to save all recognized faces\n",
    "# output_folder = 'recognized_faces'\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # Metrics variables\n",
    "# start_time = None\n",
    "# total_recognitions = 0\n",
    "# total_verifications = 0\n",
    "# average_recognition_time = 0.0\n",
    "# average_verification_rate = 0.0\n",
    "# confidence_threshold = 0.5  # Set the confidence threshold as needed\n",
    "\n",
    "# while True:\n",
    "#     # Read a frame from the video\n",
    "#     ret, frame = video.read()\n",
    "\n",
    "#     # Detect faces using face_recognition library\n",
    "#     face_locations = face_recognition.face_locations(frame)\n",
    "    \n",
    "#     # Ensure that there are face encodings\n",
    "#     if len(face_locations) > 0:\n",
    "#         face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "#         # Perform face verification\n",
    "#         for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "#             name = knn_clf.predict([face_encoding])[0]\n",
    "#             (top, right, bottom, left) = face_location\n",
    "\n",
    "#             # Perform face recognition with confidence\n",
    "#             face_distances = face_recognition.face_distance(list(verification_encodings.values()), face_encoding)\n",
    "#             min_distance = min(face_distances)\n",
    "#             if min_distance < confidence_threshold:\n",
    "#                 recognized_name = list(verification_encodings.keys())[list(face_distances).index(min_distance)]\n",
    "#             else:\n",
    "#                 recognized_name = \"Unknown\"\n",
    "\n",
    "#             # Log recognition event\n",
    "#             with open(log_file_path, 'a') as log_file:\n",
    "#                 log_file.write(f\"{datetime.datetime.now()} - Recognized: {recognized_name}\\n\")\n",
    "\n",
    "#             # Display the name of the recognized person\n",
    "#             font = cv2.FONT_HERSHEY_DUPLEX\n",
    "#             cv2.putText(frame, f\"{recognized_name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 0), 1)  # Yellow text\n",
    "\n",
    "#             # Draw a rectangle around the face\n",
    "#             cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "#             # Save the recognized face to the output folder\n",
    "#             face_image = frame[top:bottom, left:right]\n",
    "#             face_filename = os.path.join(output_folder, f\"{recognized_name}_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "#             cv2.imwrite(face_filename, face_image)\n",
    "\n",
    "#             # Update metrics\n",
    "#             total_recognitions += 1\n",
    "#             total_verifications += 1 if recognized_name != \"Unknown\" else 0\n",
    "#             if start_time is not None:\n",
    "#                 elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "#                 average_recognition_time = (average_recognition_time * (total_recognitions - 1) + elapsed_time) / total_recognitions\n",
    "#                 average_verification_rate = total_verifications / total_recognitions\n",
    "\n",
    "#             # Record start time for the next face\n",
    "#             start_time = datetime.datetime.now()\n",
    "\n",
    "#     # Display metrics on the frame\n",
    "#     cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "#     cv2.putText(frame, f\"Total Verifications: {total_verifications}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "#     cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "#     cv2.putText(frame, f\"Average Verification Rate: {average_verification_rate:.2%}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "#     # Display the frame\n",
    "#     cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# video.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3353d",
   "metadata": {},
   "source": [
    "# main in txt main code working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d01b92bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in MOULI's image: C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MOULI\\14.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'ABHI':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHI\\0.jpg',\n",
    "    'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "    'ABHIRAM':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHIRAM\\0.jpg',\n",
    "    'ABHISHIEK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHISHIEK\\0.jpg',\n",
    "    'ARUN':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ARUN\\0.jpg',\n",
    "    'BHEEMARAJU':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\BHEEMARAJU\\0.jpg',\n",
    "    'GIRISH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GIRISH\\0.jpg',\n",
    "    'GOUSE':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOUSE\\0.jpg',\n",
    "    'GOWTHAM':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\0.jpg',\n",
    "    'KARTHIK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\KARTHIK\\0.jpg',\n",
    "    'KISHORE':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\KISHORE\\0.jpg',\n",
    "    'LAVAKUMAR':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\LAVAKUMAR\\0.jpg',\n",
    "    'LOKESH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\LOKESH\\15.jpg',\n",
    "    'MAHESH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MAHESH\\14.jpg',\n",
    "    'MANIKANTA':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MANIKANTA\\39.jpg',\n",
    "    'MOULI':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MOULI\\14.jpg',\n",
    "    'SURESH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\SURESH\\14.jpg',\n",
    "    'VARDHAN':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VARDHAN\\26.jpg',\n",
    "    'VIVEK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIVEK\\14.jpg',\n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    # Ensure that at least one face is detected\n",
    "    face_encodings = face_recognition.face_encodings(verification_image)\n",
    "    if face_encodings:\n",
    "        verification_encodings[person] = face_encodings[0]\n",
    "    else:\n",
    "        print(f\"No face detected in {person}'s image: {image_path}\")\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# Log file to record recognition and verification events\n",
    "log_file_path = 'recognition_log.txt'\n",
    "\n",
    "# Folder to save all recognized faces\n",
    "output_folder = 'recognized_faces'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# File to save recognized names\n",
    "recognized_names_file_path = 'recognized_names.txt'\n",
    "\n",
    "# Metrics variables\n",
    "start_time = None\n",
    "total_recognitions = 0\n",
    "average_recognition_time = 0.0\n",
    "confidence_threshold = 0.5  # Set the confidence threshold as needed\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    \n",
    "    # Ensure that there are face encodings\n",
    "    if len(face_locations) > 0:\n",
    "        face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "        # Perform face verification\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            name = knn_clf.predict([face_encoding])[0]\n",
    "            (top, right, bottom, left) = face_location\n",
    "\n",
    "            # Perform face recognition with confidence\n",
    "            face_distances = face_recognition.face_distance(list(verification_encodings.values()), face_encoding)\n",
    "            min_distance = min(face_distances)\n",
    "            if min_distance < confidence_threshold:\n",
    "                recognized_name = list(verification_encodings.keys())[list(face_distances).index(min_distance)]\n",
    "            else:\n",
    "                recognized_name = \"Unknown\"\n",
    "\n",
    "            # Log recognition event\n",
    "            with open(log_file_path, 'a') as log_file:\n",
    "                log_file.write(f\"{datetime.datetime.now()} - Recognized: {recognized_name}\\n\")\n",
    "\n",
    "            # Display the name of the recognized person\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, f\"{recognized_name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 0), 1)  # Yellow text\n",
    "\n",
    "            # Draw a rectangle around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "            if recognized_name != \"Unknown\":\n",
    "                # Save the recognized face to the output folder\n",
    "                face_image = frame[top:bottom, left:right]\n",
    "                face_filename = os.path.join(output_folder, f\"{recognized_name}_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "                cv2.imwrite(face_filename, face_image)\n",
    "\n",
    "                # Save the recognized name to the text file\n",
    "                with open(recognized_names_file_path, 'a') as names_file:\n",
    "                    names_file.write(f\"{recognized_name}\\n\")\n",
    "\n",
    "                # Update metrics\n",
    "                total_recognitions += 1\n",
    "                if start_time is not None:\n",
    "                    elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "                    average_recognition_time = (average_recognition_time * (total_recognitions - 1) + elapsed_time) / total_recognitions\n",
    "\n",
    "            # Record start time for the next face\n",
    "            start_time = datetime.datetime.now()\n",
    "\n",
    "    # Display metrics on the frame\n",
    "    cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "    cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f1d661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9792afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffde2c8d",
   "metadata": {},
   "source": [
    "# notification  TO THE LAPTOP  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c3d6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in MOULI's image: C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MOULI\\14.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "import csv\n",
    "from plyer import notification\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'ABHI': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHI\\0.jpg',\n",
    "    'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "    'ABHIRAM':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHIRAM\\0.jpg',\n",
    "    'ABHISHIEK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHISHIEK\\0.jpg',\n",
    "    'ARUN':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ARUN\\0.jpg',\n",
    "    'BHEEMARAJU':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\BHEEMARAJU\\0.jpg',\n",
    "    'GIRISH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GIRISH\\0.jpg',\n",
    "    'GOUSE':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOUSE\\0.jpg',\n",
    "    'GOWTHAM':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\0.jpg',\n",
    "    'KARTHIK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\KARTHIK\\0.jpg',\n",
    "    'KISHORE':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\KISHORE\\0.jpg',\n",
    "    'LAVAKUMAR':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\LAVAKUMAR\\0.jpg',\n",
    "    'LOKESH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\LOKESH\\15.jpg',\n",
    "    'MAHESH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MAHESH\\14.jpg',\n",
    "    'MANIKANTA':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MANIKANTA\\39.jpg',\n",
    "    'MOULI':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MOULI\\14.jpg',\n",
    "    'SURESH':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\SURESH\\14.jpg',\n",
    "    'VARDHAN':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VARDHAN\\26.jpg',\n",
    "    'VIVEK':r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIVEK\\14.jpg',\n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    # Ensure that at least one face is detected\n",
    "    face_encodings = face_recognition.face_encodings(verification_image)\n",
    "    if face_encodings:\n",
    "        verification_encodings[person] = face_encodings[0]\n",
    "    else:\n",
    "        print(f\"No face detected in {person}'s image: {image_path}\")\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# CSV file to record recognition and verification events\n",
    "csv_file_path = 'recognition_log.csv'\n",
    "\n",
    "# Folder to save all recognized faces\n",
    "output_folder = 'recognized_faces'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# File to save recognized names\n",
    "recognized_names_file_path = 'recognized_names.txt'\n",
    "\n",
    "# Metrics variables\n",
    "start_time = None\n",
    "total_recognitions = 0\n",
    "average_recognition_time = 0.0\n",
    "confidence_threshold = 0.5  # Set the confidence threshold as needed\n",
    "\n",
    "# CSV columns\n",
    "csv_columns = ['Timestamp', 'Name']\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n",
    "    writer.writeheader()\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "\n",
    "    # Ensure that there are face encodings\n",
    "    if len(face_locations) > 0:\n",
    "        face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "        # Perform face verification\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            name = knn_clf.predict([face_encoding])[0]\n",
    "            (top, right, bottom, left) = face_location\n",
    "\n",
    "            # Perform face recognition with confidence\n",
    "            face_distances = face_recognition.face_distance(list(verification_encodings.values()), face_encoding)\n",
    "            min_distance = min(face_distances)\n",
    "            if min_distance < confidence_threshold:\n",
    "                recognized_name = list(verification_encodings.keys())[list(face_distances).index(min_distance)]\n",
    "            else:\n",
    "                recognized_name = \"Unknown\"\n",
    "\n",
    "            # Log recognition event\n",
    "            with open(csv_file_path, 'a', newline='') as csv_file:\n",
    "                writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n",
    "                writer.writerow({'Timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'Name': recognized_name})\n",
    "\n",
    "            # Display the name of the recognized person\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, f\"{recognized_name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 0), 1)  # Yellow text\n",
    "\n",
    "            # Draw a rectangle around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "            if recognized_name != \"Unknown\":\n",
    "                # Save the recognized face to the output folder\n",
    "                face_image = frame[top:bottom, left:right]\n",
    "                face_filename = os.path.join(output_folder,\n",
    "                                             f\"{recognized_name}_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "                cv2.imwrite(face_filename, face_image)\n",
    "\n",
    "                # Save the recognized name to the text file\n",
    "                with open(recognized_names_file_path, 'a') as names_file:\n",
    "                    names_file.write(f\"{recognized_name}\\n\")\n",
    "\n",
    "                # Display notification\n",
    "                notification_title = \"Face Recognition\"\n",
    "                notification_text = f\"Recognized: {recognized_name}\"\n",
    "                notification.notify(title=notification_title, message=notification_text, app_icon=None, timeout=10)\n",
    "\n",
    "                # Update metrics\n",
    "                total_recognitions += 1\n",
    "                if start_time is not None:\n",
    "                    elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "                    average_recognition_time = (\n",
    "                            average_recognition_time * (total_recognitions - 1) + elapsed_time) / total_recognitions\n",
    "\n",
    "            # Record start time for the next face\n",
    "            start_time = datetime.datetime.now()\n",
    "\n",
    "    # Display metrics on the frame\n",
    "    cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                (0, 255, 255), 2)  # Yellow text\n",
    "    cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee95530",
   "metadata": {},
   "source": [
    "# notification to the laptop main code *****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29abe182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in MOULI's image: C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MOULI\\14.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "import csv\n",
    "from plyer import notification\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'ABHI': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHI\\0.jpg',\n",
    "    'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "    'ABHIRAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHIRAM\\0.jpg',\n",
    "    'ABHISHIEK': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHISHIEK\\0.jpg',\n",
    "    'ARUN': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ARUN\\0.jpg',\n",
    "    'BHEEMARAJU': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\BHEEMARAJU\\0.jpg',\n",
    "    'GIRISH': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GIRISH\\0.jpg',\n",
    "    'GOUSE': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOUSE\\0.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\0.jpg',\n",
    "    'KARTHIK': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\KARTHIK\\0.jpg',\n",
    "    'KISHORE': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\KISHORE\\0.jpg',\n",
    "    'LAVAKUMAR': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\LAVAKUMAR\\0.jpg',\n",
    "    'LOKESH': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\LOKESH\\15.jpg',\n",
    "    'MAHESH': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MAHESH\\14.jpg',\n",
    "    'MANIKANTA': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MANIKANTA\\39.jpg',\n",
    "    'MOULI': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MOULI\\14.jpg',\n",
    "    'SURESH': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\SURESH\\14.jpg',\n",
    "    'VARDHAN': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VARDHAN\\26.jpg',\n",
    "    'VIVEK': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIVEK\\14.jpg',\n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    # Ensure that at least one face is detected\n",
    "    face_encodings = face_recognition.face_encodings(verification_image)\n",
    "    if face_encodings:\n",
    "        verification_encodings[person] = face_encodings[0]\n",
    "    else:\n",
    "        print(f\"No face detected in {person}'s image: {image_path}\")\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# CSV file to record recognition and verification events\n",
    "csv_file_path = 'recognition_log.csv'\n",
    "\n",
    "# Folder to save all recognized faces\n",
    "output_folder = 'recognized_faces'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# File to save recognized names\n",
    "recognized_names_file_path = 'recognized_names.txt'\n",
    "\n",
    "# Metrics variables\n",
    "start_time = None\n",
    "total_recognitions = 0\n",
    "average_recognition_time = 0.0\n",
    "confidence_threshold = 0.5  # Set the confidence threshold as needed\n",
    "\n",
    "# CSV columns\n",
    "csv_columns = ['Timestamp', 'Year', 'Month', 'Date', 'Hour', 'Minute', 'Second', 'Name']\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n",
    "    writer.writeheader()\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "\n",
    "    # Ensure that there are face encodings\n",
    "    if len(face_locations) > 0:\n",
    "        face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "        # Perform face verification\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            name = knn_clf.predict([face_encoding])[0]\n",
    "            (top, right, bottom, left) = face_location\n",
    "\n",
    "            # Perform face recognition with confidence\n",
    "            face_distances = face_recognition.face_distance(list(verification_encodings.values()), face_encoding)\n",
    "            min_distance = min(face_distances)\n",
    "            if min_distance < confidence_threshold:\n",
    "                recognized_name = list(verification_encodings.keys())[list(face_distances).index(min_distance)]\n",
    "            else:\n",
    "                recognized_name = \"Unknown\"\n",
    "\n",
    "            # Log recognition event\n",
    "            with open(csv_file_path, 'a', newline='') as csv_file:\n",
    "                timestamp = datetime.datetime.now()\n",
    "                writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n",
    "                writer.writerow({\n",
    "                    'Timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'Year': timestamp.year,\n",
    "                    'Month': timestamp.month,\n",
    "                    'Date': timestamp.day,\n",
    "                    'Hour': timestamp.hour,\n",
    "                    'Minute': timestamp.minute,\n",
    "                    'Second': timestamp.second,\n",
    "                    'Name': recognized_name\n",
    "                })\n",
    "\n",
    "            # Display the name of the recognized person\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, f\"{recognized_name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 0), 1)  # Yellow text\n",
    "\n",
    "            # Draw a rectangle around the face\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "            if recognized_name != \"Unknown\":\n",
    "                # Save the recognized face to the output folder\n",
    "                face_image = frame[top:bottom, left:right]\n",
    "                face_filename = os.path.join(output_folder,\n",
    "                                             f\"{recognized_name}_{timestamp.strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "                cv2.imwrite(face_filename, face_image)\n",
    "\n",
    "                # Save the recognized name to the text file\n",
    "                with open(recognized_names_file_path, 'a') as names_file:\n",
    "                    names_file.write(f\"{recognized_name}\\n\")\n",
    "\n",
    "                # Display notification\n",
    "                notification_title = \"Face Recognition\"\n",
    "                notification_text = f\"Recognized: {recognized_name}\"\n",
    "                notification.notify(title=notification_title, message=notification_text, app_icon=None, timeout=10)\n",
    "\n",
    "                # Update metrics\n",
    "                total_recognitions += 1\n",
    "                if start_time is not None:\n",
    "                    elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "                    average_recognition_time = (\n",
    "                            average_recognition_time * (total_recognitions - 1) + elapsed_time) / total_recognitions\n",
    "\n",
    "            # Record start time for the next face\n",
    "            start_time = datetime.datetime.now()\n",
    "\n",
    "    # Display metrics on the frame\n",
    "    cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                (0, 255, 255), 2)  # Yellow text\n",
    "    cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b6588",
   "metadata": {},
   "source": [
    "# alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b866bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import face_recognition\n",
    "# import pickle\n",
    "# import datetime\n",
    "# import os\n",
    "# import csv\n",
    "# from pydub import AudioSegment\n",
    "# # import simpleaudio\n",
    "# from plyer import notification\n",
    "\n",
    "# # Load the trained KNN classifier\n",
    "# with open('trained_model.clf', 'rb') as f:\n",
    "#     knn_clf = pickle.load(f)\n",
    "\n",
    "# # Dictionary to store verification images and their encodings\n",
    "# verification_images = {\n",
    "#     'ABHI': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHI\\0.jpg',\n",
    "#     'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "#     'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "#     'ABHIRAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHIRAM\\0.jpg',\n",
    "#     'ABHISHIEK': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHISHIEK\\0.jpg',\n",
    "#     'ARUN': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ARUN\\0.jpg',\n",
    "#     'BHEEMARAJU': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\BHEEMARAJU\\0.jpg',\n",
    "#     'GIRISH': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GIRISH\\0.jpg',\n",
    "#     'GOUSE': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOUSE\\0.jpg',\n",
    "#     'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\0.jpg',\n",
    "#     'KARTHIK': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\KARTHIK\\0.jpg',\n",
    "#     'KISHORE': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\KISHORE\\0.jpg',\n",
    "#     'LAVAKUMAR': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\LAVAKUMAR\\0.jpg',\n",
    "#     'LOKESH': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\LOKESH\\15.jpg',\n",
    "#     'MAHESH': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MAHESH\\14.jpg',\n",
    "#     'MANIKANTA': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MANIKANTA\\39.jpg',\n",
    "#     'MOULI': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MOULI\\14.jpg',\n",
    "#     'SURESH': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\SURESH\\14.jpg',\n",
    "#     'VARDHAN': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VARDHAN\\26.jpg',\n",
    "#     'VIVEK': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIVEK\\14.jpg',\n",
    "#     # Add your verification images and paths\n",
    "# }\n",
    "\n",
    "# # Load verification images and their encodings\n",
    "# verification_encodings = {}\n",
    "# for person, image_path in verification_images.items():\n",
    "#     verification_image = face_recognition.load_image_file(image_path)\n",
    "#     # Ensure that at least one face is detected\n",
    "#     face_encodings = face_recognition.face_encodings(verification_image)\n",
    "#     if face_encodings:\n",
    "#         verification_encodings[person] = face_encodings[0]\n",
    "#     else:\n",
    "#         print(f\"No face detected in {person}'s image: {image_path}\")\n",
    "\n",
    "# # Open the video capture\n",
    "# video = cv2.VideoCapture(1)\n",
    "\n",
    "# # CSV file to record recognition and verification events\n",
    "# csv_file_path = 'recognition_log.csv'\n",
    "\n",
    "# # Folder to save all recognized faces\n",
    "# output_folder = 'recognized_faces'\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # File to save recognized names\n",
    "# recognized_names_file_path = 'recognized_names.txt'\n",
    "\n",
    "# # Metrics variables\n",
    "# start_time = None\n",
    "# total_recognitions = 0\n",
    "# average_recognition_time = 0.0\n",
    "# confidence_threshold = 0.5  # Set the confidence threshold as needed\n",
    "\n",
    "# # CSV columns\n",
    "# csv_columns = ['Timestamp', 'Name']\n",
    "\n",
    "# with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "#     writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n",
    "#     writer.writeheader()\n",
    "\n",
    "# # Alarm parameters\n",
    "# alarm_triggered = False\n",
    "# alarm_duration = 5  # seconds\n",
    "\n",
    "# # Load and play the alarm sound\n",
    "# alarm_path = 'alarm1.mp3'  # Replace with your MP3 file\n",
    "# alarm_sound = AudioSegment.from_mp3(alarm_path)\n",
    "\n",
    "# while True:\n",
    "#     # Read a frame from the video\n",
    "#     ret, frame = video.read()\n",
    "\n",
    "#     # Detect faces using face_recognition library\n",
    "#     face_locations = face_recognition.face_locations(frame)\n",
    "\n",
    "#     # Ensure that there are face encodings\n",
    "#     if len(face_locations) > 0:\n",
    "#         face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "#         # Perform face verification\n",
    "#         for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "#             name = knn_clf.predict([face_encoding])[0]\n",
    "#             (top, right, bottom, left) = face_location\n",
    "\n",
    "#             # Perform face recognition with confidence\n",
    "#             face_distances = face_recognition.face_distance(list(verification_encodings.values()), face_encoding)\n",
    "#             min_distance = min(face_distances)\n",
    "#             if min_distance < confidence_threshold:\n",
    "#                 recognized_name = list(verification_encodings.keys())[list(face_distances).index(min_distance)]\n",
    "#             else:\n",
    "#                 recognized_name = \"Unknown\"\n",
    "\n",
    "#             # Log recognition event\n",
    "#             with open(csv_file_path, 'a', newline='') as csv_file:\n",
    "#                 timestamp = datetime.datetime.now()\n",
    "#                 writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n",
    "#                 writer.writerow({'Timestamp': timestamp.strftime('%Y-%m-%d %H:%M:%S'), 'Name': recognized_name})\n",
    "\n",
    "#             # Display the name of the recognized person\n",
    "#             font = cv2.FONT_HERSHEY_DUPLEX\n",
    "#             cv2.putText(frame, f\"{recognized_name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 0), 1)  # Yellow text\n",
    "\n",
    "#             # Draw a rectangle around the face\n",
    "#             cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "#             if recognized_name != \"Unknown\":\n",
    "#                 # Save the recognized face to the output folder\n",
    "#                 face_image = frame[top:bottom, left:right]\n",
    "#                 face_filename = os.path.join(output_folder,\n",
    "#                                              f\"{recognized_name}_{timestamp.strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "#                 cv2.imwrite(face_filename, face_image)\n",
    "\n",
    "#                 # Save the recognized name to the text file\n",
    "#                 with open(recognized_names_file_path, 'a') as names_file:\n",
    "#                     names_file.write(f\"{recognized_name}\\n\")\n",
    "\n",
    "#                 # Display notification\n",
    "#                 notification_title = \"Face Recognition\"\n",
    "#                 notification_text = f\"Recognized: {recognized_name}\"\n",
    "#                 notification.notify(title=notification_title, message=notification_text, app_icon=None, timeout=10)\n",
    "\n",
    "#                 # Update metrics\n",
    "#                 total_recognitions += 1\n",
    "#                 if start_time is not None:\n",
    "#                     elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "#                     average_recognition_time = (\n",
    "#                             average_recognition_time * (total_recognitions - 1) + elapsed_time) / total_recognitions\n",
    "\n",
    "#                 # Trigger alarm\n",
    "#                 if not alarm_triggered:\n",
    "#                     # Play the alarm sound\n",
    "#                     playback_obj = simpleaudio.play_buffer(alarm_sound.raw_data, num_channels=1,\n",
    "#                                                            bytes_per_sample=alarm_sound.sample_width,\n",
    "#                                                            sample_rate=alarm_sound.frame_rate)\n",
    "#                     playback_obj.wait_done()  # Wait for the playback to finish\n",
    "#                     alarm_triggered = True\n",
    "#                     alarm_start_time = datetime.datetime.now()\n",
    "\n",
    "#                 # Check if the alarm duration has passed\n",
    "#                 if alarm_triggered and (datetime.datetime.now() - alarm_start_time).total_seconds() > alarm_duration:\n",
    "#                     alarm_triggered = False\n",
    "\n",
    "#             # Record start time for the next face\n",
    "#             start_time = datetime.datetime.now()\n",
    "\n",
    "#     # Display metrics on the frame\n",
    "#     cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "#                 (0, 255, 255), 2)  # Yellow text\n",
    "#     cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 60),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "#     # Display the frame\n",
    "#     cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# video.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0bb9e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (2.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# pip install plyer \n",
    "pip install pygame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818ef842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simpleaudio\n",
      "  Using cached simpleaudio-1.0.4.tar.gz (2.0 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: simpleaudio\n",
      "  Building wheel for simpleaudio (setup.py): started\n",
      "  Building wheel for simpleaudio (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for simpleaudio\n",
      "Failed to build simpleaudio\n",
      "Installing collected packages: simpleaudio\n",
      "  Running setup.py install for simpleaudio: started\n",
      "  Running setup.py install for simpleaudio: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [18 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\simpleaudio\n",
      "  copying simpleaudio\\__init__.py -> build\\lib.win-amd64-cpython-39\\simpleaudio\n",
      "  copying simpleaudio\\shiny.py -> build\\lib.win-amd64-cpython-39\\simpleaudio\n",
      "  copying simpleaudio\\functionchecks.py -> build\\lib.win-amd64-cpython-39\\simpleaudio\n",
      "  creating build\\lib.win-amd64-cpython-39\\simpleaudio\\test_audio\n",
      "  copying simpleaudio\\test_audio\\c.wav -> build\\lib.win-amd64-cpython-39\\simpleaudio\\test_audio\n",
      "  copying simpleaudio\\test_audio\\e.wav -> build\\lib.win-amd64-cpython-39\\simpleaudio\\test_audio\n",
      "  copying simpleaudio\\test_audio\\g.wav -> build\\lib.win-amd64-cpython-39\\simpleaudio\\test_audio\n",
      "  copying simpleaudio\\test_audio\\left_right.wav -> build\\lib.win-amd64-cpython-39\\simpleaudio\\test_audio\n",
      "  copying simpleaudio\\test_audio\\notes_2_16_44.wav -> build\\lib.win-amd64-cpython-39\\simpleaudio\\test_audio\n",
      "  running build_ext\n",
      "  building 'simpleaudio._simpleaudio' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for simpleaudio\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for simpleaudio did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [31 lines of output]\n",
      "  running install\n",
      "  C:\\Users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages\\setuptools\\_distutils\\cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Please avoid running ``setup.py`` directly.\n",
      "          Instead, use pypa/build, pypa/installer or other\n",
      "          standards-based tools.\n",
      "  \n",
      "          See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    self.initialize_options()\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-39\n",
      "  creating build\\lib.win-amd64-cpython-39\\simpleaudio\n",
      "  copying simpleaudio\\__init__.py -> build\\lib.win-amd64-cpython-39\\simpleaudio\n",
      "  copying simpleaudio\\shiny.py -> build\\lib.win-amd64-cpython-39\\simpleaudio\n",
      "  copying simpleaudio\\functionchecks.py -> build\\lib.win-amd64-cpython-39\\simpleaudio\n",
      "  creating build\\lib.win-amd64-cpython-39\\simpleaudio\\test_audio\n",
      "  copying simpleaudio\\test_audio\\c.wav -> build\\lib.win-amd64-cpython-39\\simpleaudio\\test_audio\n",
      "  copying simpleaudio\\test_audio\\e.wav -> build\\lib.win-amd64-cpython-39\\simpleaudio\\test_audio\n",
      "  copying simpleaudio\\test_audio\\g.wav -> build\\lib.win-amd64-cpython-39\\simpleaudio\\test_audio\n",
      "  copying simpleaudio\\test_audio\\left_right.wav -> build\\lib.win-amd64-cpython-39\\simpleaudio\\test_audio\n",
      "  copying simpleaudio\\test_audio\\notes_2_16_44.wav -> build\\lib.win-amd64-cpython-39\\simpleaudio\\test_audio\n",
      "  running build_ext\n",
      "  building 'simpleaudio._simpleaudio' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "simpleaudio\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install simpleaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2514c84",
   "metadata": {},
   "source": [
    "# streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae1d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path = 'recognition_log.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Streamlit app\n",
    "st.title('Face Recognition Log Viewer')\n",
    "\n",
    "# Display the dataframe\n",
    "st.write(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f73e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run face.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a9c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbae0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479791c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d97f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad603ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79237e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7082ce77",
   "metadata": {},
   "source": [
    "# NOTIFICATION AS SMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379c5132",
   "metadata": {},
   "outputs": [
    {
     "ename": "TwilioRestException",
     "evalue": "HTTP 400 error: Unable to create record: Invalid 'To' Phone Number: +1202759XXXX",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTwilioRestException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13596\\1919480748.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrecognized_name\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"Unknown\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[1;31m# Send SMS notification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 message = client.messages.create(\n\u001b[0m\u001b[0;32m     76\u001b[0m                     \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf\"Face Recognized: {recognized_name}\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                     \u001b[0mfrom_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtwilio_phone_number\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\vijaykumar\\lib\\site-packages\\twilio\\rest\\api\\v2010\\account\\message\\__init__.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, to, status_callback, application_sid, max_price, provide_feedback, attempt, validity_period, force_delivery, content_retention, address_retention, smart_encoded, persistent_action, shorten_urls, schedule_type, send_at, send_as_mms, content_variables, risk_check, from_, messaging_service_sid, body, media_url, content_sid)\u001b[0m\n\u001b[0;32m    558\u001b[0m         )\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         payload = self._version.create(\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"POST\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0muri\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\vijaykumar\\lib\\site-packages\\twilio\\base\\version.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, method, uri, params, data, headers, auth, timeout, allow_redirects)\u001b[0m\n\u001b[0;32m    463\u001b[0m         )\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     async def create_async(\n",
      "\u001b[1;32m~\\anaconda3\\vijaykumar\\lib\\site-packages\\twilio\\base\\version.py\u001b[0m in \u001b[0;36m_parse_create\u001b[1;34m(self, method, uri, response)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \"\"\"\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Unable to create record\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTwilioRestException\u001b[0m: HTTP 400 error: Unable to create record: Invalid 'To' Phone Number: +1202759XXXX"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "from twilio.rest import Client\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'ABHI': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHI\\0.jpg',\n",
    "    'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    # Ensure that at least one face is detected\n",
    "    face_encodings = face_recognition.face_encodings(verification_image)\n",
    "    if face_encodings:\n",
    "        verification_encodings[person] = face_encodings[0]\n",
    "    else:\n",
    "        print(f\"No face detected in {person}'s image: {image_path}\")\n",
    "\n",
    "# Twilio credentials\n",
    "account_sid = 'AC6bc114c4600c291336ab938b5873e31e'\n",
    "auth_token = '8ad27dfdbf8807095e2c3f0b76391a81'\n",
    "twilio_phone_number = '+12027596106'\n",
    "destination_phone_number = '+12027596106'\n",
    "\n",
    "# Twilio client\n",
    "client = Client(account_sid, auth_token)\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# Metrics variables\n",
    "start_time = None\n",
    "total_recognitions = 0\n",
    "average_recognition_time = 0.0\n",
    "confidence_threshold = 0.5  # Set the confidence threshold as needed\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "\n",
    "    # Ensure that there are face encodings\n",
    "    if len(face_locations) > 0:\n",
    "        face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "        # Perform face verification\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            name = knn_clf.predict([face_encoding])[0]\n",
    "            (top, right, bottom, left) = face_location\n",
    "\n",
    "            # Perform face recognition with confidence\n",
    "            face_distances = face_recognition.face_distance(list(verification_encodings.values()), face_encoding)\n",
    "            min_distance = min(face_distances)\n",
    "            if min_distance < confidence_threshold:\n",
    "                recognized_name = list(verification_encodings.keys())[list(face_distances).index(min_distance)]\n",
    "            else:\n",
    "                recognized_name = \"Unknown\"\n",
    "\n",
    "            if recognized_name != \"Unknown\":\n",
    "                # Send SMS notification\n",
    "                message = client.messages.create(\n",
    "                    body=f\"Face Recognized: {recognized_name}\",\n",
    "                    from_=twilio_phone_number,\n",
    "                    to=destination_phone_number\n",
    "                )\n",
    "\n",
    "            # Update metrics\n",
    "            total_recognitions += 1\n",
    "            if start_time is not None:\n",
    "                elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "                average_recognition_time = (average_recognition_time * (total_recognitions - 1) + elapsed_time) / total_recognitions\n",
    "\n",
    "            # Record start time for the next face\n",
    "            start_time = datetime.datetime.now()\n",
    "\n",
    "    # Display metrics on the frame\n",
    "    cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                (0, 255, 255), 2)  # Yellow text\n",
    "    cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5597392b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8efadd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca7162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6eff4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64209a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plivo in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (4.47.0)\n",
      "Requirement already satisfied: lxml<5,>=3 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from plivo) (4.9.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from plivo) (2.28.1)\n",
      "Requirement already satisfied: decorator<5,>=4 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from plivo) (4.4.2)\n",
      "Requirement already satisfied: six<2,>=1 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from plivo) (1.16.0)\n",
      "Requirement already satisfied: PyJWT in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from plivo) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from requests<3,>=2->plivo) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from requests<3,>=2->plivo) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from requests<3,>=2->plivo) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from requests<3,>=2->plivo) (2022.9.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install plivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a2c3ba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plivo' from 'plivo' (C:\\Users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages\\plivo\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17804\\2852785379.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mplivo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplivo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Set your Plivo Auth ID and Auth Token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mauth_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'your_plivo_auth_id'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mauth_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'your_plivo_auth_token'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'plivo' from 'plivo' (C:\\Users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages\\plivo\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from plivo import plivo\n",
    "\n",
    "# Set your Plivo Auth ID and Auth Token\n",
    "auth_id = 'your_plivo_auth_id'\n",
    "auth_token = 'your_plivo_auth_token'\n",
    "\n",
    "# Create a Plivo REST client\n",
    "client = plivo.RestClient(auth_id=auth_id, auth_token=auth_token)\n",
    "\n",
    "# Specify the sender's phone number (Plivo number)\n",
    "from_number = 'your_plivo_phone_number'\n",
    "\n",
    "# Specify the recipient's phone number\n",
    "to_number = 'recipient_phone_number'\n",
    "\n",
    "# Specify the message\n",
    "message = 'Hello, this is a test message from Plivo!'\n",
    "\n",
    "# Send the message\n",
    "response = client.messages.create(\n",
    "    src=from_number,\n",
    "    dst=to_number,\n",
    "    text=message\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c67985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d270b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a474e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f353d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5831b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d54b5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154607c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import face_recognition\n",
    "# import pickle\n",
    "# import datetime\n",
    "\n",
    "# # Your existing code...\n",
    "\n",
    "# # Train the KNN classifier if needed\n",
    "# # (Assuming you have a function or code to train the KNN classifier)\n",
    "# # knn_clf = train_knn_classifier()\n",
    "\n",
    "# # Save the trained KNN classifier using pickle\n",
    "# with open('trained_model.clf', 'wb') as f:\n",
    "#     pickle.dump(knn_clf, f)\n",
    "\n",
    "# # Continue with the rest of your script...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe6478",
   "metadata": {},
   "source": [
    "# save in folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d7dab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import face_recognition\n",
    "# import pickle\n",
    "# import datetime\n",
    "# import csv\n",
    "# import os\n",
    "\n",
    "# # Load the trained KNN classifier\n",
    "# with open('trained_model.clf', 'rb') as f:\n",
    "#     knn_clf = pickle.load(f)\n",
    "\n",
    "# # Dictionary to store verification images and their encodings\n",
    "# verification_images = {\n",
    "#     'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "#     'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "#     # Add more persons as needed\n",
    "# }\n",
    "\n",
    "# # Load verification images and their encodings\n",
    "# verification_encodings = {}\n",
    "# for person, image_path in verification_images.items():\n",
    "#     verification_image = face_recognition.load_image_file(image_path)\n",
    "#     verification_encodings[person] = face_recognition.face_encodings(verification_image)[0]\n",
    "\n",
    "# # Open the video capture\n",
    "# video = cv2.VideoCapture(1)\n",
    "\n",
    "# # Folder to save recognized faces\n",
    "# output_folder = 'recognized_faces'\n",
    "\n",
    "# # Create the output folder if it doesn't exist\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # Metrics variables\n",
    "# start_time = None\n",
    "# total_recognitions = 0\n",
    "# total_verifications = 0\n",
    "# average_recognition_time = 0.0\n",
    "# average_verification_rate = 0.0\n",
    "\n",
    "# # Open the CSV file in write mode\n",
    "# csv_file_path = 'recognized_names.csv'\n",
    "# with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "#     # Create a CSV writer object\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "\n",
    "#     while True:\n",
    "#         # Read a frame from the video\n",
    "#         ret, frame = video.read()\n",
    "\n",
    "#         # Detect faces using face_recognition library\n",
    "#         face_locations = face_recognition.face_locations(frame)\n",
    "#         face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "#         # Perform face verification\n",
    "#         for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "#             name = knn_clf.predict([face_encoding])[0]\n",
    "#             (top, right, bottom, left) = face_location\n",
    "\n",
    "#             # Log recognition event\n",
    "#             csv_writer.writerow([name])\n",
    "#             total_recognitions += 1\n",
    "\n",
    "#             # Draw a rectangle around the face\n",
    "#             cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "#             # Perform face verification with multiple verification images\n",
    "#             for person, encoding in verification_encodings.items():\n",
    "#                 verification_result = face_recognition.compare_faces([encoding], face_encoding)\n",
    "#                 if verification_result[0]:\n",
    "#                     # Log verification event\n",
    "#                     with open('recognition_log.txt', 'a') as log_file:\n",
    "#                         log_file.write(f\"{datetime.datetime.now()} - Verified: {person}\\n\")\n",
    "#                     total_verifications += 1\n",
    "\n",
    "#                     # Save the recognized face to the output folder\n",
    "#                     face_image = frame[top:bottom, left:right]\n",
    "#                     face_filename = os.path.join(output_folder, f\"{name}_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "#                     cv2.imwrite(face_filename, face_image)\n",
    "\n",
    "#                     # Display the name of the recognized and verified person\n",
    "#                     font = cv2.FONT_HERSHEY_DUPLEX\n",
    "#                     cv2.putText(frame, f\"{name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "#         # Update metrics\n",
    "#         if start_time is not None and total_recognitions > 1:\n",
    "#             elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "#             average_recognition_time = (average_recognition_time * (total_recognitions - 1) + elapsed_time) / (total_recognitions - 1)\n",
    "#             average_verification_rate = total_verifications / (total_recognitions - 1) if (total_recognitions - 1) > 0 else 0\n",
    "\n",
    "#         # Record start time for the next face\n",
    "#         start_time = datetime.datetime.now()\n",
    "\n",
    "#         # Display metrics on the frame\n",
    "#         cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "#         cv2.putText(frame, f\"Total Verifications: {total_verifications}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "#         cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "#         cv2.putText(frame, f\"Average Verification Rate: {average_verification_rate:.2%}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "#         # Display the frame\n",
    "#         cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "#         # Break the loop if 'q' is pressed\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# video.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d450309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f058bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import face_recognition\n",
    "# import pickle\n",
    "# import datetime\n",
    "# import csv\n",
    "# import os\n",
    "\n",
    "# # Load the trained KNN classifier\n",
    "# with open('trained_model.clf', 'rb') as f:\n",
    "#     knn_clf = pickle.load(f)\n",
    "\n",
    "# # Dictionary to store verification images and their encodings\n",
    "# verification_images = {\n",
    "#     'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "#     'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "#     # Add more persons as needed\n",
    "# }\n",
    "\n",
    "# # Load verification images and their encodings\n",
    "# verification_encodings = {}\n",
    "# for person, image_path in verification_images.items():\n",
    "#     verification_image = face_recognition.load_image_file(image_path)\n",
    "#     verification_encodings[person] = face_recognition.face_encodings(verification_image)[0]\n",
    "\n",
    "# # Open the video capture\n",
    "# video = cv2.VideoCapture(1)\n",
    "\n",
    "# # Folder to save recognized faces\n",
    "# output_folder = 'recognized_faces'\n",
    "\n",
    "# # Create the output folder if it doesn't exist\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # Metrics variables\n",
    "# start_time = None\n",
    "# total_recognitions = 0\n",
    "# total_verifications = 0\n",
    "# average_recognition_time = 0.0\n",
    "# average_verification_rate = 0.0\n",
    "\n",
    "# # Open the CSV file in write mode\n",
    "# csv_file_path = 'recognized_names.csv'\n",
    "# with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "#     # Create a CSV writer object\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "\n",
    "#     while True:\n",
    "#         # Read a frame from the video\n",
    "#         ret, frame = video.read()\n",
    "\n",
    "#         # Detect faces using face_recognition library\n",
    "#         face_locations = face_recognition.face_locations(frame)\n",
    "#         face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "#         # Perform face verification\n",
    "#         for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "#             name = knn_clf.predict([face_encoding])[0]\n",
    "#             (top, right, bottom, left) = face_location\n",
    "\n",
    "#             # Log recognition event\n",
    "#             csv_writer.writerow([name])\n",
    "#             total_recognitions += 1\n",
    "\n",
    "#             # Draw a rectangle around the face\n",
    "#             cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "#             # Perform face verification with multiple verification images\n",
    "#             for person, encoding in verification_encodings.items():\n",
    "#                 verification_result = face_recognition.compare_faces([encoding], face_encoding)\n",
    "#                 if verification_result[0]:\n",
    "#                     # Log verification event\n",
    "#                     with open('recognition_log.txt', 'a') as log_file:\n",
    "#                         log_file.write(f\"{datetime.datetime.now()} - Verified: {person}\\n\")\n",
    "#                     total_verifications += 1\n",
    "\n",
    "#                     # Save the recognized face to the output folder\n",
    "#                     face_image = frame[top:bottom, left:right]\n",
    "#                     face_filename = os.path.join(output_folder, f\"{name}_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "#                     cv2.imwrite(face_filename, face_image)\n",
    "\n",
    "#                     # Display the name of the recognized and verified person\n",
    "#                     font = cv2.FONT_HERSHEY_DUPLEX\n",
    "#                     cv2.putText(frame, f\"{person}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "#                 else:\n",
    "#                     # Display a generic label for unrecognized faces\n",
    "#                     cv2.putText(frame, \"Unknown\", (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "#         # Update metrics\n",
    "#         if start_time is not None and total_recognitions > 1:\n",
    "#             elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "#             average_recognition_time = (average_recognition_time * (total_recognitions - 1) + elapsed_time) / (total_recognitions - 1)\n",
    "#             average_verification_rate = total_verifications / (total_recognitions - 1) if (total_recognitions - 1) > 0 else 0\n",
    "\n",
    "#         # Record start time for the next face\n",
    "#         start_time = datetime.datetime.now()\n",
    "\n",
    "#         # Display metrics on the frame\n",
    "#         cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "#         cv2.putText(frame, f\"Total Verifications: {total_verifications}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "#         cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "#         cv2.putText(frame, f\"Average Verification Rate: {average_verification_rate:.2%}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "#         # Display the frame\n",
    "#         cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "#         # Break the loop if 'q' is pressed\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# video.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ce4d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import face_recognition\n",
    "# import pickle\n",
    "# import datetime\n",
    "# import csv\n",
    "# import os\n",
    "\n",
    "# # Load the trained KNN classifier\n",
    "# with open('trained_model.clf', 'rb') as f:\n",
    "#     knn_clf = pickle.load(f)\n",
    "\n",
    "# # Open the video capture\n",
    "# video = cv2.VideoCapture(1)\n",
    "\n",
    "# # Folder to save recognized faces\n",
    "# output_folder = 'recognized_faces'\n",
    "\n",
    "# # Create the output folder if it doesn't exist\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# # Metrics variables\n",
    "# start_time = None\n",
    "# total_recognitions = 0\n",
    "# total_verifications = 0\n",
    "# average_recognition_time = 0.0\n",
    "# average_verification_rate = 0.0\n",
    "\n",
    "# # Open the CSV file in write mode\n",
    "# csv_file_path = 'recognized_names.csv'\n",
    "# with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "#     # Create a CSV writer object\n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "\n",
    "#     while True:\n",
    "#         # Read a frame from the video\n",
    "#         ret, frame = video.read()\n",
    "\n",
    "#         # Detect faces using face_recognition library\n",
    "#         face_locations = face_recognition.face_locations(frame)\n",
    "#         face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "#         # Perform face recognition\n",
    "#         for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "#             name = knn_clf.predict([face_encoding])[0]\n",
    "#             (top, right, bottom, left) = face_location\n",
    "\n",
    "#             # Log recognition event\n",
    "#             csv_writer.writerow([name])\n",
    "#             total_recognitions += 1\n",
    "\n",
    "#             # Draw a rectangle around the face\n",
    "#             cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "#             # Display the name of the recognized person\n",
    "#             font = cv2.FONT_HERSHEY_DUPLEX\n",
    "#             cv2.putText(frame, f\"{name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "#         # Update metrics\n",
    "#         if start_time is not None and total_recognitions > 1:\n",
    "#             elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "#             average_recognition_time = (average_recognition_time * (total_recognitions - 1) + elapsed_time) / (total_recognitions - 1)\n",
    "#             average_verification_rate = total_verifications / (total_recognitions - 1) if (total_recognitions - 1) > 0 else 0\n",
    "\n",
    "#         # Record start time for the next face\n",
    "#         start_time = datetime.datetime.now()\n",
    "\n",
    "#         # Display metrics on the frame\n",
    "#         cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "#         cv2.putText(frame, f\"Total Verifications: {total_verifications}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "#         cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "#         cv2.putText(frame, f\"Average Verification Rate: {average_verification_rate:.2%}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "#         # Display the frame\n",
    "#         cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "#         # Break the loop if 'q' is pressed\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# video.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c4493",
   "metadata": {},
   "source": [
    "# data log save folder main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b99ca150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import datetime\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "    'ABHI' : r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\ABHI\\0.jpg',\n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    verification_encodings[person] = face_recognition.face_encodings(verification_image)[0]\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# Folder to save recognized faces\n",
    "output_folder = 'recognized_faces'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Metrics variables\n",
    "start_time = None\n",
    "total_recognitions = 0\n",
    "total_verifications = 0\n",
    "average_recognition_time = 0.0\n",
    "average_verification_rate = 0.0\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "csv_file_path = 'recognized_names.csv'\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = video.read()\n",
    "\n",
    "        # Detect faces using face_recognition library\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "        face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "        # Perform face recognition\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            name = knn_clf.predict([face_encoding])[0]\n",
    "            (top, right, bottom, left) = face_location\n",
    "\n",
    "            # Log recognition event\n",
    "            csv_writer.writerow([name])\n",
    "            total_recognitions += 1\n",
    "\n",
    "            # Draw a rectangle around the face\n",
    "            if name in verification_encodings:\n",
    "                # Save the recognized face to the output folder\n",
    "                face_image = frame[top:bottom, left:right]\n",
    "                face_filename = os.path.join(output_folder, f\"{name}_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.jpg\")\n",
    "                cv2.imwrite(face_filename, face_image)\n",
    "\n",
    "                # Display the name of the recognized person\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, f\"{name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)  # Green rectangle for recognized faces\n",
    "            else:\n",
    "                # Display a dot for unrecognized faces\n",
    "                cv2.circle(frame, (left + (right - left) // 2, top + (bottom - top) // 2), 5, (0, 0, 255), -1)\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)  # Red rectangle for unrecognized faces\n",
    "\n",
    "            # Perform face verification with multiple verification images\n",
    "            for person, encoding in verification_encodings.items():\n",
    "                verification_result = face_recognition.compare_faces([encoding], face_encoding)\n",
    "                if verification_result[0]:\n",
    "                    # Log verification event\n",
    "                    with open('recognition_log.txt', 'a') as log_file:\n",
    "                        log_file.write(f\"{datetime.datetime.now()} - Verified: {person}\\n\")\n",
    "                    total_verifications += 1\n",
    "\n",
    "        # Update metrics\n",
    "        if start_time is not None and total_recognitions > 1:\n",
    "            elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "            average_recognition_time = (average_recognition_time * (total_recognitions - 1) + elapsed_time) / (total_recognitions - 1)\n",
    "            average_verification_rate = total_verifications / (total_recognitions - 1) if (total_recognitions - 1) > 0 else 0\n",
    "\n",
    "        # Record start time for the next face\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # Display metrics on the frame\n",
    "        cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "        cv2.putText(frame, f\"Total Verifications: {total_verifications}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "        cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "        cv2.putText(frame, f\"Average Verification Rate: {average_verification_rate:.2%}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c653af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in MOULI's image: C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\MOULI\\14.jpg\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef3d1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f54c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dbc51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c241736c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d5188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5156d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12a8a443",
   "metadata": {},
   "source": [
    "# notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c62941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "def send_email(sender, receiver, password, smtp_server, smtp_port, subject, body):\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    msg['Subject'] = subject\n",
    "    msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "    with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
    "        server.starttls()\n",
    "        server.login(sender, password)\n",
    "        text = msg.as_string()\n",
    "        server.sendmail(sender, receiver, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482c9979",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21844\\826690372.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0maverage_recognition_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maverage_recognition_time\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtotal_recognitions\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0melapsed_time\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_recognitions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0maverage_verification_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_verifications\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal_recognitions\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtotal_recognitions\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import datetime\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    verification_encodings[person] = face_recognition.face_encodings(verification_image)[0]\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# Log file to record recognition and verification events\n",
    "log_file_path = 'recognition_log.txt'\n",
    "\n",
    "# Email configuration\n",
    "email_sender = 'vijaykumarpenke123@gmail.com'\n",
    "email_receiver = 'abhiramaryan93@gmail.com'\n",
    "email_password = 'abhi@123'\n",
    "smtp_server = 'smtp.gmail.com'\n",
    "smtp_port = 587\n",
    "\n",
    "# Metrics variables\n",
    "start_time = None\n",
    "total_recognitions = 0\n",
    "total_verifications = 0\n",
    "average_recognition_time = 0.0\n",
    "average_verification_rate = 0.0\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "    # Perform face verification\n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        name = knn_clf.predict([face_encoding])[0]\n",
    "        (top, right, bottom, left) = face_location\n",
    "\n",
    "        # Log recognition event\n",
    "        with open(log_file_path, 'a') as log_file:\n",
    "            log_file.write(f\"{datetime.datetime.now()} - Recognized: {name}\\n\")\n",
    "        total_recognitions += 1\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        # Perform face verification with multiple verification images\n",
    "        for person, encoding in verification_encodings.items():\n",
    "            verification_result = face_recognition.compare_faces([encoding], face_encoding)\n",
    "            if verification_result[0]:\n",
    "                # Log verification event\n",
    "                with open(log_file_path, 'a') as log_file:\n",
    "                    log_file.write(f\"{datetime.datetime.now()} - Verified: {person}\\n\")\n",
    "                total_verifications += 1\n",
    "\n",
    "                # Display the name of the recognized and verified person\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, f\"{name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "                # Send email notification\n",
    "                subject = 'Person Identified'\n",
    "                body = f\"The person {name} has been identified.\"\n",
    "                send_email(email_sender, email_receiver, email_password, smtp_server, smtp_port, subject, body)\n",
    "\n",
    "    # Update metrics\n",
    "    if start_time is not None:\n",
    "        elapsed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "        average_recognition_time = (average_recognition_time * (total_recognitions - 1) + elapsed_time) / total_recognitions\n",
    "        average_verification_rate = total_verifications / total_recognitions if total_recognitions > 0 else 0\n",
    "\n",
    "    # Record start time for the next face\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    # Display metrics on the frame\n",
    "    cv2.putText(frame, f\"Total Recognitions: {total_recognitions}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "    cv2.putText(frame, f\"Total Verifications: {total_verifications}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "    cv2.putText(frame, f\"Average Recognition Time: {average_recognition_time:.2f} seconds\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "    cv2.putText(frame, f\"Average Verification Rate: {average_verification_rate:.2%}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)  # Yellow text\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def send_email(sender, receiver, password, smtp_server, smtp_port, subject, body):\n",
    "    msg = MIMEMultipart()\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    msg['Subject'] = subject\n",
    "    msg.attach(MIMEText(body, 'plain'))\n",
    "\n",
    "    with smtplib.SMTP(smtp_server, smtp_port) as server:\n",
    "        server.starttls()\n",
    "        server.login(sender, password)\n",
    "        text = msg.as_string()\n",
    "        server.sendmail(sender, receiver, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe6af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea3b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec9ed848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with out total recogniton and total verification\n",
    "\n",
    "# import cv2\n",
    "# import face_recognition\n",
    "# import pickle\n",
    "# import datetime\n",
    "\n",
    "# # Load the trained KNN classifier\n",
    "# with open('trained_model.clf', 'rb') as f:\n",
    "#     knn_clf = pickle.load(f)\n",
    "\n",
    "# # Dictionary to store verification images and their encodings\n",
    "# verification_images = {\n",
    "#     'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "#     'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "#     # Add more persons as needed\n",
    "# }\n",
    "\n",
    "# # Load verification images and their encodings\n",
    "# verification_encodings = {}\n",
    "# for person, image_path in verification_images.items():\n",
    "#     verification_image = face_recognition.load_image_file(image_path)\n",
    "#     verification_encodings[person] = face_recognition.face_encodings(verification_image)[0]\n",
    "\n",
    "# # Open the video capture\n",
    "# video = cv2.VideoCapture(1)\n",
    "\n",
    "# # Log file to record recognition and verification events\n",
    "# log_file_path = 'recognition_log.txt'\n",
    "\n",
    "# while True:\n",
    "#     # Read a frame from the video\n",
    "#     ret, frame = video.read()\n",
    "\n",
    "#     # Detect faces using face_recognition library\n",
    "#     face_locations = face_recognition.face_locations(frame)\n",
    "#     face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "#     # Perform face verification\n",
    "#     for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "#         name = knn_clf.predict([face_encoding])[0]\n",
    "#         (top, right, bottom, left) = face_location\n",
    "\n",
    "#         # Log recognition event\n",
    "#         with open(log_file_path, 'a') as log_file:\n",
    "#             log_file.write(f\"{datetime.datetime.now()} - Recognized: {name}\\n\")\n",
    "\n",
    "#         # Log additional details of the person\n",
    "#         with open(log_file_path, 'a') as log_file:\n",
    "#             log_file.write(f\"Name: {name}\\n\")\n",
    "\n",
    "#         # Display the name of the recognized and verified person\n",
    "#         font = cv2.FONT_HERSHEY_DUPLEX\n",
    "#         cv2.putText(frame, f\"{name}\", (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "#         # Draw a rectangle around the face\n",
    "#         cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "#     # Display the frame\n",
    "#     cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# video.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c883023",
   "metadata": {},
   "source": [
    "# calculate and display some simple metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba5b88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Recognitions: 8\n",
      "Total Verifications: 9\n",
      "Average Verification Rate: 112.50%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "# Load the trained KNN classifier\n",
    "with open('trained_model.clf', 'rb') as f:\n",
    "    knn_clf = pickle.load(f)\n",
    "\n",
    "# Dictionary to store verification images and their encodings\n",
    "verification_images = {\n",
    "    'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "    'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "    # Add more persons as needed\n",
    "}\n",
    "\n",
    "# Load verification images and their encodings\n",
    "verification_encodings = {}\n",
    "for person, image_path in verification_images.items():\n",
    "    verification_image = face_recognition.load_image_file(image_path)\n",
    "    verification_encodings[person] = face_recognition.face_encodings(verification_image)[0]\n",
    "\n",
    "# Open the video capture\n",
    "video = cv2.VideoCapture(1)\n",
    "\n",
    "# Log file to record recognition and verification events\n",
    "log_file_path = 'recognition_log.txt'\n",
    "\n",
    "# Metrics variables\n",
    "total_recognitions = 0\n",
    "total_verifications = 0\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # Detect faces using face_recognition library\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "    # Perform face verification\n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        name = knn_clf.predict([face_encoding])[0]\n",
    "        (top, right, bottom, left) = face_location\n",
    "\n",
    "        # Log recognition event\n",
    "        with open(log_file_path, 'a') as log_file:\n",
    "            log_file.write(f\"{datetime.datetime.now()} - Recognized: {name}\\n\")\n",
    "        total_recognitions += 1\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        # Perform face verification with multiple verification images\n",
    "        for person, encoding in verification_encodings.items():\n",
    "            verification_result = face_recognition.compare_faces([encoding], face_encoding)\n",
    "            if verification_result[0]:\n",
    "                # Log verification event\n",
    "                with open(log_file_path, 'a') as log_file:\n",
    "                    log_file.write(f\"{datetime.datetime.now()} - Verified: {name} as {person}\\n\")\n",
    "                total_verifications += 1\n",
    "\n",
    "                # Display the name of the recognized and verified person\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, f\"{name} (Verified as {person})\", (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Calculate and display metrics\n",
    "average_verification_rate = total_verifications / total_recognitions if total_recognitions > 0 else 0\n",
    "print(f\"Total Recognitions: {total_recognitions}\")\n",
    "print(f\"Total Verifications: {total_verifications}\")\n",
    "print(f\"Average Verification Rate: {average_verification_rate:.2%}\")\n",
    "\n",
    "# Release the video capture and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27fd5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca230e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3811cba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc6a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1302bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef363005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twilio\n",
      "  Using cached twilio-8.10.3-py2.py3-none-any.whl (1.8 MB)\n",
      "Collecting aiohttp-retry>=2.8.3\n",
      "  Downloading aiohttp_retry-2.8.3-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from twilio) (2.4.0)\n",
      "Collecting aiohttp>=3.8.4\n",
      "  Using cached aiohttp-3.9.1-cp39-cp39-win_amd64.whl (365 kB)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from twilio) (2.28.1)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp39-cp39-win_amd64.whl (44 kB)\n",
      "     --------------------------------------- 44.7/44.7 kB 43.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (1.8.1)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from aiohttp>=3.8.4->twilio) (21.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from requests>=2.0.0->twilio) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from requests>=2.0.0->twilio) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from requests>=2.0.0->twilio) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages (from requests>=2.0.0->twilio) (2.0.4)\n",
      "Installing collected packages: frozenlist, async-timeout, aiosignal, aiohttp, aiohttp-retry, twilio\n",
      "Successfully installed aiohttp-3.9.1 aiohttp-retry-2.8.3 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.0 twilio-8.10.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\vijay\\anaconda3\\vijaykumar\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install twilio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2d7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import face_recognition\n",
    "# import pickle\n",
    "# import datetime\n",
    "# from twilio.rest import Client\n",
    "\n",
    "# # Load the trained KNN classifier\n",
    "# with open('trained_model.clf', 'rb') as f:\n",
    "#     knn_clf = pickle.load(f)\n",
    "\n",
    "# # Dictionary to store verification images and their encodings\n",
    "# verification_images = {\n",
    "#     'VIJAY': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\VIJAY\\1.jpg',\n",
    "#     'GOWTHAM': r'C:\\Users\\vijay\\Documents\\chando 55 face_recognition_project-main\\FINAL\\DATASET\\GOWTHAM\\40.jpg',\n",
    "#     # Add more persons as needed\n",
    "# }\n",
    "\n",
    "# # Load verification images and their encodings\n",
    "# verification_encodings = {}\n",
    "# for person, image_path in verification_images.items():\n",
    "#     verification_image = face_recognition.load_image_file(image_path)\n",
    "#     verification_encodings[person] = face_recognition.face_encodings(verification_image)[0]\n",
    "\n",
    "# # Open the video capture\n",
    "# video = cv2.VideoCapture(1)\n",
    "\n",
    "# # Log file to record recognition and verification events\n",
    "# log_file_path = 'recognition_log.txt'\n",
    "\n",
    "# # Twilio credentials\n",
    "# account_sid = 'your_twilio_account_sid'\n",
    "# auth_token = 'your_twilio_auth_token'\n",
    "# twilio_phone_number = 'your_twilio_phone_number'\n",
    "# your_phone_number = 'your_phone_number_to_receive_notifications'\n",
    "\n",
    "# # Twilio client\n",
    "# client = Client(account_sid, auth_token)\n",
    "\n",
    "# while True:\n",
    "#     # Read a frame from the video\n",
    "#     ret, frame = video.read()\n",
    "\n",
    "#     # Detect faces using face_recognition library\n",
    "#     face_locations = face_recognition.face_locations(frame)\n",
    "#     face_encodings = face_recognition.face_encodings(frame, known_face_locations=face_locations)\n",
    "\n",
    "#     # Perform face verification\n",
    "#     for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "#         name = knn_clf.predict([face_encoding])[0]\n",
    "#         (top, right, bottom, left) = face_location\n",
    "\n",
    "#         # Log recognition event\n",
    "#         with open(log_file_path, 'a') as log_file:\n",
    "#             log_file.write(f\"{datetime.datetime.now()} - Recognized: {name}\\n\")\n",
    "\n",
    "#         # Draw a rectangle around the face\n",
    "#         cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "#         # Perform face verification with multiple verification images\n",
    "#         for person, encoding in verification_encodings.items():\n",
    "#             verification_result = face_recognition.compare_faces([encoding], face_encoding)\n",
    "#             if verification_result[0]:\n",
    "#                 # Log verification event\n",
    "#                 with open(log_file_path, 'a') as log_file:\n",
    "#                     log_file.write(f\"{datetime.datetime.now()} - Verified: {name} as {person}\\n\")\n",
    "\n",
    "#                 # Display the name of the recognized and verified person\n",
    "#                 font = cv2.FONT_HERSHEY_DUPLEX\n",
    "#                 cv2.putText(frame, f\"{name} (Verified as {person})\", (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "#                 # Send Twilio SMS notification\n",
    "#                 message = client.messages.create(\n",
    "#                     body=f\"Person {name} verified as {person}\",\n",
    "#                     from_=twilio_phone_number,\n",
    "#                     to=your_phone_number\n",
    "#                 )\n",
    "\n",
    "#     # Display the frame\n",
    "#     cv2.imshow(\"Face Recognition and Verification\", frame)\n",
    "\n",
    "#     # Break the loop if 'q' is pressed\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the video capture and close all windows\n",
    "# video.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf18ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
